{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN6/6cw0wNLsVrK46f/uMyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VAZaytsev/FlowerClassifier/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flower classifier\n",
        "We construct the flower classifier on the basis of the [dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/), consisting of 102 flower classes. In each class, there are from 40 to 258 images. To convert each image into a feature vector we will use a pre-trained convolutional neural network ResNet-50, which was first presented in this [preprint](https://arxiv.org/abs/1512.03385) and currently can be found in many machine learning frameworks. Here we will use TensorFlow.\n",
        "\n",
        "Similar projects can be found [here](https://towardsdatascience.com/build-train-and-deploy-a-real-world-flower-classifier-of-102-flower-types-a90f66d2092a) and [here](https://www.kaggle.com/code/dtosidis/flower-classifier-tensorflow/notebook). "
      ],
      "metadata": {
        "id": "AaWzp34KHNxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's load the necessary packages for visualizing the data"
      ],
      "metadata": {
        "id": "t7IK3_04m4Ir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBZCu5FPqAZI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we load everything needed for the creation of the classifier from TensorFlow"
      ],
      "metadata": {
        "id": "LsIbfoxgnYFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.layers.core import Dense\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "GK-bJak-qIwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now load the dataset with the flowers images from TensorFlow (some details can be found in a [documentation](https://www.tensorflow.org/datasets/catalog/oxford_flowers102))"
      ],
      "metadata": {
        "id": "PR0MKaFknsAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds, ds_info = tfds.load('oxford_flowers102', \n",
        "                        with_info=True, \n",
        "                        as_supervised=True)"
      ],
      "metadata": {
        "id": "xd9NaJ-XxrFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print the number of classes and the sizes of the training, validation, and testing datasets. Following the original [paper](https://www.robots.ox.ac.uk/~vgg/publications/2008/Nilsback08/), for both the training and validation sets from each class 10 images are taken (1020 images per each set). The testing set consists of the remaining 6149 images. Note that in such separation the size of the testing set is much larger that the ones of the training and validation. "
      ],
      "metadata": {
        "id": "T1Laj-xGoZAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Nclasses = ds_info.features['label'].num_classes\n",
        "print('Number of classes = ', Nclasses)\n",
        "\n",
        "print('Training set size = ', len(ds['train']) )\n",
        "print('Validation set size = ', len(ds['validation']) )\n",
        "print('Testing set size = ', len(ds['test']) )"
      ],
      "metadata": {
        "id": "_i3vwsjxoWGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how do the images look like"
      ],
      "metadata": {
        "id": "1zCwsMw4p2Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "N = 2\n",
        "\n",
        "pos = 0\n",
        "for image, label in ds['train'].take(N**2):\n",
        "  name = ds_info.features['label'].names[int(label)]\n",
        "  ax = plt.subplot(N, N, pos + 1)\n",
        "  plt.imshow(image.numpy())\n",
        "  plt.title( name + ' (' + str(int(label)) + ')' )\n",
        "  plt.axis(\"off\")\n",
        "  pos = pos + 1"
      ],
      "metadata": {
        "id": "6_EymJvKyN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now turn to the construction of the model. The shape of the input layer is D x D x 3, where D is the size of the image and additional dimension 3 encodes the colors. The input layer is followed by the network ResNet-50 with fixed weights, which won't be changed in course of training. An output layer has one neuron per class, in our case that is 102 neurons. The function below will construct and compile the model."
      ],
      "metadata": {
        "id": "lBLFz_8OqG6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model(learning_rate=0.001, image_size=224):\n",
        "  URL = \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5\"\n",
        "  feature_extractor = hub.KerasLayer(URL, \n",
        "                                     input_shape=(image_size, image_size, 3), \n",
        "                                     trainable=False)\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = Sequential([feature_extractor, \n",
        "                      #Flatten(), \n",
        "                      Dense(Nclasses, activation='softmax')])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aC9KmHSbJoyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training the model one needs to preprocess the images and prepare the data sets. Initially, the size of an image from the data set is at least 500 in each dimension. One needs to rescale it to a given size. Moreover, the value of each color should be mapped to the range [0,1] from [0,255]. We also separate the dataset into butches and shuffle the data (if needed). Here we shuffle the complete data set following TensorFlow [tips](https://www.tensorflow.org/datasets/performances). For the details about [cache](https://www.tensorflow.org/guide/data_performance#caching) and [prefetch](https://www.tensorflow.org/guide/data_performance#prefetching), we refer to the documentation. "
      ],
      "metadata": {
        "id": "LOxFZFHfu5e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data_set, batch_size=32, image_size=224, shuffle=True):\n",
        "\n",
        "  def parse_image(image, label):\n",
        "    image = tf.image.resize(image, (image_size, image_size)) / 255.0 #Normalizes images: `uint8` -> `float32`.\n",
        "    return image, label\n",
        "\n",
        "  data_set = data_set.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  #data_set = data_set.cache()\n",
        "  if shuffle:\n",
        "    data_set = data_set.shuffle(len(data_set))\n",
        "  data_set = data_set.batch(batch_size)\n",
        "  data_set = data_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  return data_set"
      ],
      "metadata": {
        "id": "NhG4WI642Jk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now set the parameters and train the model. Here we use the parameters which minimize the validation loss. It appeared that the most important parameter is the image size. If it is too small, e.g. 180, the accuracy of the validation set is relatively small. It is also unnecessary to use a size bigger than 300 since it doesn't influence accuracy anymore."
      ],
      "metadata": {
        "id": "OrAF75aQ0vFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters \n",
        "epochs = 20\n",
        "image_size = 300\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Clear session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Create the model\n",
        "model = prepare_model(learning_rate=learning_rate, image_size=image_size)\n",
        "model.summary()\n",
        "\n",
        "train_ds = prepare_data(ds['train'], batch_size=batch_size, image_size=image_size)\n",
        "\n",
        "# There is no need to shuffle validation or testing data \n",
        "validation_ds = prepare_data(ds['validation'], batch_size=batch_size, image_size=image_size, shuffle=False)\n",
        "test_ds = prepare_data(ds['test'], batch_size=batch_size, image_size=image_size, shuffle=False)"
      ],
      "metadata": {
        "id": "AL9bTkEO9dqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, \n",
        "                    validation_data=validation_ds, \n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "id": "js3AkMjy4k_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training curve looks as follows."
      ],
      "metadata": {
        "id": "TqXa7m3bUxyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "epochs_range= range(epochs)\n",
        "\n",
        "plt.plot( epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
        "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "plt.axis(ymin=0.0,ymax=1)\n",
        "plt.grid()\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])"
      ],
      "metadata": {
        "id": "4UTLOrZmDxtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now check the performance of our model on the testing set."
      ],
      "metadata": {
        "id": "6uzbAQueVBxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_ds)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "id": "3YRoN7hY45RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the accuracy obtained in the original work is 0.728 meanwhile here we reached 0.84."
      ],
      "metadata": {
        "id": "XCDr2aU5AWNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nice part\n",
        "Of course we now can analyse the results, e.g. plot an accuracy for each class, find most difficult flowers to recognize and etc. But this is not so interesting. I decided to check like which flower my wife will be classified. For this purpose we need to load couple of photos and process them properly. "
      ],
      "metadata": {
        "id": "8Cx9tEi0N82u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def process_img(img):\n",
        "  img_np = np.asarray(img)\n",
        "  img_tf = tf.image.resize(img_np, (image_size, image_size)) / 255.0\n",
        "  img_tf = np.expand_dims(img_tf, axis=0)\n",
        "  return img_tf"
      ],
      "metadata": {
        "id": "jYRjN603BVyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we load the photos, make predictions, and for each photo we choose 3 flower classes, which fits most."
      ],
      "metadata": {
        "id": "zarkFG16-6QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = Image.open('m1.jpg')\n",
        "m2 = Image.open('m2.jpg')\n",
        "\n",
        "m1_tf = process_img(m1)\n",
        "m2_tf = process_img(m2)\n",
        "\n",
        "vals1, labels1 = tf.math.top_k( model.predict(m1_tf, verbose=0), 3)\n",
        "vals2, labels2 = tf.math.top_k( model.predict(m2_tf, verbose=0), 3)\n",
        "\n",
        "labels1 = np.squeeze(labels1.numpy()).tolist()\n",
        "labels2 = np.squeeze(labels2.numpy()).tolist()\n",
        "\n",
        "vals1 = [round(100*x) for x in np.squeeze(vals1.numpy()).tolist()]\n",
        "vals2 = [round(100*x) for x in np.squeeze(vals2.numpy()).tolist()]"
      ],
      "metadata": {
        "id": "2iVJHWMyE8jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now pick the corresponding flower samples from the data set."
      ],
      "metadata": {
        "id": "7bGhXaFe_NZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs1 = []\n",
        "imgs2 = []\n",
        "for image, label in ds['test']:\n",
        "  l1 = len(imgs1)\n",
        "  if l1 < 3:\n",
        "    if int(label) == int(labels1[l1]):\n",
        "      img_scld = tf.image.resize(image, (image_size, image_size)) / 255.0\n",
        "      imgs1.append(img_scld)\n",
        "\n",
        "  l2 = len(imgs2)\n",
        "  if l2 < 3:\n",
        "    if int(label) == int(labels2[l2]):\n",
        "      img_scld = tf.image.resize(image, (image_size, image_size)) / 255.0\n",
        "      imgs2.append(img_scld)\n",
        "\n",
        "  if l1 == 3 and l2 == 3:\n",
        "    break"
      ],
      "metadata": {
        "id": "qLgdk6btJQCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the pictures!"
      ],
      "metadata": {
        "id": "wQagwWdN_TNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "ax = plt.subplot(1, 4, 1)\n",
        "plt.imshow(m1)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "for i,x in enumerate(imgs1):\n",
        "  ax = plt.subplot(1, 4, 2+i)\n",
        "  name = ds_info.features['label'].names[labels1[i]]\n",
        "  plt.title( str(vals1[i]) + '% ' + name )\n",
        "  plt.imshow(x.numpy())\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "8r_NLviuJnmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "ax = plt.subplot(1, 4, 1)\n",
        "plt.imshow(m2)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "for i,x in enumerate(imgs2):\n",
        "  ax = plt.subplot(1, 4, 2+i)\n",
        "  name = ds_info.features['label'].names[labels2[i]]\n",
        "  plt.title( str(vals2[i]) + '% ' + name )\n",
        "  plt.imshow(x.numpy())\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "eGNPMSLGJ9-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}